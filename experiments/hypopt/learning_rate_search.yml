## study name is mandatory
study_name : learning_rate_search
## parameters to optimize, mandatory
parameters : [
  trainer.optimizer.args.lr : {
    suggestion : suggest_discrete_uniform,
    args : {
      low : 0.0001,
      high : 0.001,
      q : 0.00005,
    }
  },
  trainer.lr_scheduler.args.warmup_t : {
    suggestion : suggest_int,
    args : {
      low : 2,
      high : 5,
    }
  },
]
objective : {
  module : TrainObjective,
  args : {
    metric_type : val, ## [val, loss]
    metric_name : accuracy, ## if metric_type==val
    ## final objective value is the reduced validation metrics
    reduction : average, # reduction is based on numpy function (e.g. np.average, np.max, etc.)
    reduction_args : {
      weights : [1, 2, 3, 4, 5]
    }
  }
}
## configuration for optuna study, mandatory field
study : {
  n_trials : 5,
  direction : maximize,
  ## optional
  pruner : {
    method : MedianPruner,
    args : {},
  },
  sampler : {
    method : TPESampler,
    # method : CmaEsSampler,
    args : {},
  },
  ## optional args will be forwarded to optuna
  args : {
    # storage : sqlite:///experiments/outputs/hypopt/darknet53_yolov3_voc2007_loss.db,
    # load_if_exists : True,
  }
}
## param to be added to config, mandatory but can be empty
additional_config : {}
## param to override but not to be optimized, this field is mandatory but can be empty
override : {
  ## train for 10 epoch and evaluate every 2 epoch, resulting 5 validation metrics
  trainer.epoch: 10,
  validator.val_epoch: 2,
}
## TODO : logging
# logging : {
#   project_name : voc2007-hypopt,
#   workspace : hyperion-rg
# }
