experiment_name: squeezenet_MNIST
logging: None
dataset: {
  train: {
    dataset: MNIST,
    args: {
      root: datasets,
      train: True,
      download: True
    },
  },
  eval: {
    dataset: MNIST,
    args: {
      root: datasets,
      train: False,
      download: True
    }
  },
  dataloader: {
    dataloader: DataLoader,
    args: {
      num_workers: 0,
      batch_size: 32,
      shuffle: True,
    },
  },
}
model: {
  name: softmax,
  network_args: {
    backbone: squeezenetv1.1,
    pretrained_backbone: True,
    n_classes: 10,
  },
  preprocess_args: {
    input_size: 32,
    input_normalization: {
      mean: [0.4914, 0.4822, 0.4465],
      std: [0.2023, 0.1994, 0.2010],
      scaler: 255,
    }
  },
  loss_args: {
    reduction: mean
  },
  postprocess_args: {}
}
trainer: {
  optimizer: {
    method: SGD,
    args: {
      lr: 0.001,
      momentum: 0.9,
      weight_decay: 0.0005,
    }
  },
  scheduler : {
    method : CosineLRScheduler,
    args : {
      t_initial : 20,
      t_mul : 1.0,
      lr_min : 0.00001,
      warmup_lr_init: 0.00001,
      warmup_t: 5,
      cycle_limit : 1,
      t_in_epochs : True,
      decay_rate : 0.1,
    }
  },
  validation: {
    args: {},
    val_epoch: 4,
  },
  device: 'cuda:0',
  driver: {
    module: DefaultTrainer,
    args: {
      accumulation_step: 8,
    }
  },
  epoch: 20,
  save_epoch: 5
}
output_directory: experiments/outputs
exporter : {
  module : onnx,
  args : {
    opset_version : 11,
  },
}