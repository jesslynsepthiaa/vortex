###############################################
# Creating configuration file for custom models
# =============================================
# 
# `experiment_name` is required and for this
# experiment, we'll just place experiment outputs
# at `experiments/outputs` directory

experiment_name: detr
output_directory: experiments/outputs

###############################################
# Model section
# -------------
# This section describes our model components
#
# `name` defines model name used in this config and
# should be supported. We add `detr` by registering
# custom model in `detr.py`
#
# For the purpose of demonstration, we will use
# pretrained `detr` model from facebookreasearch/detr
# 
# `input_size` and `input_normalization` are required
# by `vortex`. For now, input normalization 
# follows original `detr` demo program.
#
# We do not supports training for now, 
# so we'll ust leave `loss_args` empty.
#
# In `detr.py`, our `DETRPostProcess` module
# doesn't need initializers, so we leave `postpocess_args` empty.

model: {
  name: detr,
  network_args: {
    pretrained: True,
    num_classes: 91,
  },
  preprocess_args: {
    input_size: 800,
    input_normalization: {
      mean: [0.485, 0.456, 0.406],
      std: [0.229, 0.224, 0.225],
    }
  },
  loss_args: {},
  postprocess_args: {},
}

###############################################
# Export section
# -------------
# This section describes our specification for exporting
#
# Expected sctructure are `List[Dict[str,Any]]` 
# for multiple exports or `Dict[str,Any]` for
# single exports
#
# Here, we'll export to `onnx` and `torchscript`.
# Note that current detr implementation doesn't support batched input yet.

exporter : [
  {
    module : onnx,
    args : {
      opset_version : 11,
    },
  },
  {
    module : torchscript,
    args : {},
  },
  {
    module : torchscript,
    args : {
      n_batch: 4,
      filename: detr-bs4,
    },
  },
]

###############################################
# Dataset section
# -------------
# This section describes our dataset and dataloader

logging: None
dataset: {
  train: {
    dataset: COCO,
    args: {
      root: datasets,
      train: True,
      download: True
    },
  },
  eval: {
    dataset: COCO,
    args: {
      root: datasets,
      train: False,
      download: True
    }
  },
  dataloader: {
    dataloader: DataLoader,
    args: {
      num_workers: 0,
      batch_size: 32,
      shuffle: True,
    },
  },
}